{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3af1dd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Conditional VAE...\n",
      "Epoch 10/100\tAverage Loss: 1.524517\n",
      "Epoch 20/100\tAverage Loss: 1.437921\n",
      "Epoch 30/100\tAverage Loss: 1.372953\n",
      "Epoch 40/100\tAverage Loss: 1.347630\n",
      "Epoch 50/100\tAverage Loss: 1.345514\n",
      "Epoch 60/100\tAverage Loss: 1.345271\n",
      "Epoch 70/100\tAverage Loss: 1.315832\n",
      "Epoch 80/100\tAverage Loss: 1.295861\n",
      "Epoch 90/100\tAverage Loss: 1.306209\n",
      "Epoch 100/100\tAverage Loss: 1.314967\n",
      "\n",
      "============================================================\n",
      "GENERATING DESIGNS\n",
      "============================================================\n",
      "\n",
      "Target Bending Stiffness: 50.0\n",
      "\n",
      "Generated Designs:\n",
      "------------------------------------------------------------\n",
      "#     Thickness       Height          Angle (deg)    \n",
      "------------------------------------------------------------\n",
      "1     5.6731          19.2298         48.6431        \n",
      "2     4.3776          27.0395         50.2104        \n",
      "3     5.7778          21.9993         59.7563        \n",
      "4     4.2209          29.9346         36.5709        \n",
      "5     7.0927          17.1171         38.3083        \n",
      "6     5.1438          25.0534         34.9352        \n",
      "7     7.4318          17.9710         33.9161        \n",
      "8     4.1301          26.1514         34.4376        \n",
      "9     4.9280          18.9287         34.1234        \n",
      "10    5.1533          24.7114         44.7292        \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Configuration\n",
    "INPUT_SIZE = 3  # thickness, height, angle (what we want to generate)\n",
    "CONDITION_SIZE = 1  # bending_stiffness (what we condition on)\n",
    "HIDDEN_DIM = 64\n",
    "LATENT_DIM = 8\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 100\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "device = \"cpu\"\n",
    "\n",
    "class ConditionalVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Conditional VAE that generates [thickness, height, angle] \n",
    "    given a target bending_stiffness value\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=3, condition_dim=1, hidden_dim=64, latent_dim=8):\n",
    "        super(ConditionalVAE, self).__init__()\n",
    "        \n",
    "        # Encoder: takes input + condition\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim + condition_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Latent space\n",
    "        self.mean_layer = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.logvar_layer = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # Decoder: takes latent + condition\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim + condition_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "     \n",
    "    def encode(self, x, condition):\n",
    "        # Concatenate input with condition\n",
    "        x_cond = torch.cat([x, condition], dim=1)\n",
    "        h = self.encoder(x_cond)\n",
    "        mean = self.mean_layer(h)\n",
    "        logvar = self.logvar_layer(h)\n",
    "        return mean, logvar\n",
    "    \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "    \n",
    "    def decode(self, z, condition):\n",
    "        # Concatenate latent with condition\n",
    "        z_cond = torch.cat([z, condition], dim=1)\n",
    "        return self.decoder(z_cond)\n",
    "    \n",
    "    def forward(self, x, condition):\n",
    "        mean, logvar = self.encode(x, condition)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        x_hat = self.decode(z, condition)\n",
    "        return x_hat, mean, logvar\n",
    "\n",
    "def loss_function(x, x_hat, mean, log_var):\n",
    "    \"\"\"VAE loss = Reconstruction loss + KL divergence\"\"\"\n",
    "    reconstruction_loss = nn.functional.mse_loss(x_hat, x, reduction='sum')\n",
    "    kld = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "    return reconstruction_loss + kld\n",
    "\n",
    "def train_cvae(model, optimizer, train_loader, epochs, device):\n",
    "    \"\"\"Train the conditional VAE\"\"\"\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        overall_loss = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for batch_idx, (x, condition) in enumerate(train_loader):\n",
    "            x = x.to(device)\n",
    "            condition = condition.to(device)\n",
    "            current_batch_size = x.size(0)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            x_hat, mean, log_var = model(x, condition)\n",
    "            loss = loss_function(x, x_hat, mean, log_var)\n",
    "            \n",
    "            overall_loss += loss.item()\n",
    "            total_samples += current_batch_size\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        avg_loss = overall_loss / total_samples\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}\\tAverage Loss: {avg_loss:.6f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def generate_designs(model, target_stiffness, scaler_X, scaler_y, \n",
    "                     n_samples=10, device='cpu'):\n",
    "    \"\"\"\n",
    "    Generate designs given a target bending stiffness\n",
    "    \n",
    "    Args:\n",
    "        model: Trained CVAE model\n",
    "        target_stiffness: Desired bending stiffness value\n",
    "        scaler_X: StandardScaler fitted on X (thickness, height, angle)\n",
    "        scaler_y: StandardScaler fitted on y (bending_stiffness)\n",
    "        n_samples: Number of design variations to generate\n",
    "        device: 'cpu' or 'cuda'\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of shape (n_samples, 3) with [thickness, height, angle]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Normalize the target stiffness\n",
    "        target_normalized = scaler_y.transform([[target_stiffness]])\n",
    "        target_tensor = torch.FloatTensor(target_normalized).to(device)\n",
    "        \n",
    "        # Repeat for n_samples\n",
    "        condition = target_tensor.repeat(n_samples, 1)\n",
    "        \n",
    "        # Sample from prior distribution\n",
    "        z = torch.randn(n_samples, model.mean_layer.out_features).to(device)\n",
    "        \n",
    "        # Generate designs\n",
    "        generated = model.decode(z, condition)\n",
    "        \n",
    "        # Convert back to numpy and denormalize\n",
    "        generated_np = generated.cpu().numpy()\n",
    "        designs = scaler_X.inverse_transform(generated_np)\n",
    "        \n",
    "    return designs\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and prepare data\n",
    "    df = pd.read_csv(r'../MLP/processed_bending_stiffness.csv')\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    X = df[['Thickness', 'Height', 'Angle (deg)']].values\n",
    "    y = df['Bending_Stiffness'].values.reshape(-1, 1)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    # Normalize data (IMPORTANT for VAE training!)\n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "    \n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "    y_test_scaled = scaler_y.transform(y_test)\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "    y_train_tensor = torch.FloatTensor(y_train_scaled)\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, \n",
    "                            shuffle=True, drop_last=False)\n",
    "    \n",
    "    # Initialize and train model\n",
    "    model = ConditionalVAE(\n",
    "        input_dim=INPUT_SIZE,\n",
    "        condition_dim=CONDITION_SIZE,\n",
    "        hidden_dim=HIDDEN_DIM,\n",
    "        latent_dim=LATENT_DIM\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    print(\"Training Conditional VAE...\")\n",
    "    model = train_cvae(model, optimizer, train_loader, NUM_EPOCHS, device)\n",
    "    \n",
    "    # Generate designs for a target stiffness\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"GENERATING DESIGNS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    target_stiffness = 50.0  # Example target\n",
    "    designs = generate_designs(\n",
    "        model, \n",
    "        target_stiffness, \n",
    "        scaler_X, \n",
    "        scaler_y, \n",
    "        n_samples=10, \n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTarget Bending Stiffness: {target_stiffness}\")\n",
    "    print(\"\\nGenerated Designs:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'#':<5} {'Thickness':<15} {'Height':<15} {'Angle (deg)':<15}\")\n",
    "    print(\"-\" * 60)\n",
    "    for i, design in enumerate(designs, 1):\n",
    "        print(f\"{i:<5} {design[0]:<15.4f} {design[1]:<15.4f} {design[2]:<15.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f2776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".cmecEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
