{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9e0b364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a24117ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 1 # Bending stiffness is the only input\n",
    "OUTPUT_SIZE = 3 # Thickness, Height, Angle are outputs\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32 # \n",
    "NUM_EPOCHS = 2000\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dd7ce00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 685 duplicate row(s) from the dataset.\n",
      "Shape of dataset after removing duplicates: (743, 4)\n",
      "YTest headers:\n",
      "[[  7.236  51.739  46.9  ]\n",
      " [  6.713 117.335  69.5  ]\n",
      " [  8.18   93.69   64.9  ]\n",
      " [  5.571  24.436  64.9  ]\n",
      " [  4.427  26.159  50.9  ]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\mason\\Work\\CMEC_SandwichPanel\\Models\\MLP\\processed_bending_stiffness.csv')\n",
    "\n",
    "# Remove duplicates\n",
    "initial_count = len(df)\n",
    "df = df.drop_duplicates()\n",
    "removed_count = initial_count - len(df)\n",
    "if removed_count > 0:\n",
    "    print(f\"Removed {removed_count} duplicate row(s) from the dataset.\")\n",
    "print(f\"Shape of dataset after removing duplicates: {df.shape}\")\n",
    "\n",
    "X = df[['Bending_Stiffness']]\n",
    "y = df[['Thickness', 'Height', 'Angle (deg)']] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X.values, \n",
    "    y.values, \n",
    "    test_size=TEST_SIZE, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "print(f\"YTest headers:\\n{y_test[:5]}\")\n",
    "DATASET_SIZE = len(df) # Number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa038e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "        nn.Linear(INPUT_SIZE, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        \n",
    "        nn.Linear(64, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "\n",
    "        nn.Linear(32, 16),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        \n",
    "        # Output Layer\n",
    "        nn.Linear(16, OUTPUT_SIZE)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0b235b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "X_train_tensor = torch.from_numpy(X_train.astype(np.float32))\n",
    "y_train_tensor = torch.from_numpy(y_train.astype(np.float32))\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Convert TESTING data to PyTorch Tensors\n",
    "X_test_tensor = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_test_tensor = torch.from_numpy(y_test.astype(np.float32))\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8f39df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Training ---\n",
      "\n",
      "--- Final Evaluation on Test Set ---\n",
      "\n",
      "Test Set Metrics:\n",
      "MSE: 140.4684\n",
      "RMSE: 11.8519\n",
      "MAE: 7.8166\n",
      "R-squared (R²): 0.9600\n",
      "\n",
      "Training and Evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "mae_criterion = nn.L1Loss()  # Mean Absolute Error Loss\n",
    "criterion = nn.MSELoss()  # Mean Squared Error Loss\n",
    "\n",
    "print(\"\\n--- Starting Training ---\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, targets in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * targets.size(0)\n",
    "    \n",
    "    avg_train_loss = running_loss / len(X_train)\n",
    "    \n",
    "# --- Final Evaluation on TEST SET ---\n",
    "print(\"\\n--- Final Evaluation on Test Set ---\")\n",
    "model.eval()\n",
    "total_squared_error = 0.0\n",
    "total_absolute_error = 0.0\n",
    "total_samples = 0\n",
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # MSE loss\n",
    "        mse_loss = criterion(outputs, targets)\n",
    "        total_squared_error += mse_loss.item() * targets.size(0)\n",
    "        \n",
    "        # MAE loss\n",
    "        mae_loss = mae_criterion(outputs, targets)\n",
    "        total_absolute_error += mae_loss.item() * targets.size(0)\n",
    "        \n",
    "        total_samples += targets.size(0)\n",
    "        all_targets.append(targets.cpu())\n",
    "        all_predictions.append(outputs.cpu())\n",
    "\n",
    "# Concatenate all targets and predictions\n",
    "targets_tensor = torch.cat(all_targets)\n",
    "predictions_tensor = torch.cat(all_predictions)\n",
    "\n",
    "# Calculate metrics\n",
    "mean_squared_error = total_squared_error / total_samples\n",
    "root_mean_squared_error = np.sqrt(mean_squared_error)\n",
    "mean_absolute_error = total_absolute_error / total_samples\n",
    "\n",
    "# R-squared\n",
    "ss_residual = total_squared_error\n",
    "target_mean = targets_tensor.mean()\n",
    "ss_total = ((targets_tensor - target_mean) ** 2).sum().item()\n",
    "r_squared = 1 - (ss_residual / ss_total) if ss_total != 0 else 0.0\n",
    "\n",
    "print(f'\\nTest Set Metrics:')\n",
    "print(f'MSE: {mean_squared_error:.4f}')\n",
    "print(f'RMSE: {root_mean_squared_error:.4f}')\n",
    "print(f'MAE: {mean_absolute_error:.4f}')\n",
    "print(f'R-squared (R²): {r_squared:.4f}')\n",
    "print(\"\\nTraining and Evaluation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69ebc215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.3055, 30.4648, 40.3275]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model(torch.tensor([[802.0]], dtype=torch.float32)))  # Example bending stiffness input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd40e773",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmecVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
